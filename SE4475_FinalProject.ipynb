{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TXxzNq7ENeU",
        "outputId": "62bbcd38-5ad7-4c26-c4db-a7928fa14fa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rarfile in /usr/local/lib/python3.11/dist-packages (4.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unrar is already the newest version (1:6.1.5-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install rarfile\n",
        "!apt-get install unrar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFO1FN5gFBbt",
        "outputId": "a8ddf603-dab3-475d-cdbe-5e7a686a4c24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file was extracted successfully.\n"
          ]
        }
      ],
      "source": [
        "import rarfile\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Path of uploaded file\n",
        "rar_path = '/content/finalDataset.rar'\n",
        "\n",
        "# Extract folder path\n",
        "extracted_folder = '/content/finalDataset'\n",
        "\n",
        "# Open and extract the file\n",
        "with rarfile.RarFile(rar_path) as rf:\n",
        "    rf.extractall(extracted_folder)\n",
        "\n",
        "print(\"The file was extracted successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIA08iufFWtg",
        "outputId": "05f1d4e9-a0ce-4353-f58e-4d715bc7d7dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of articles: 1500\n",
            "Total number of labels: 1500\n",
            "Sample article: İnönü'de iki farklı devre\n",
            "Beşiktaş, rahat oynadı, çok gol kaçırdı ama Karabük o kadar dağınık ve kötü ki bu maç için fazla bir şey söylemenin de bir anlamı yok. İlk devre maça bakıyoruz 5-0 olurdu. Ek...\n",
            "Sample label: AHMET ÇAKAR\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Extracted folder path\n",
        "data_path = '/content/finalDataset/makaleler-yazarlar'\n",
        "\n",
        "# Class mapping consisting of authors\n",
        "authors = [\n",
        "    \"AHMET ÇAKAR\", \"ALİ SİRMEN\", \"ATAOL BEHRAMOĞLU\", \"ATİLLA DORSAY\", \"AYKAN SEVER\",\n",
        "    \"AZİZ ÜSTEL\", \"CAN ATAKLI\", \"DENİZ GÖKÇE\", \"EMRE KONGAR\", \"GÖZDE BEDELOĞLU\",\n",
        "    \"HASAN PULUR\", \"HİKMET ÇETİNKAYA\", \"MEHMET ALİ BİRAND\", \"MEHMET DEMİRKOL\",\n",
        "    \"MELTEM GÜRLE\", \"MERYEM KORAY\", \"MÜMTAZ SOYSAL\", \"NAZAN BEKİROĞLU\",\n",
        "    \"NAZIM ALPMAN\", \"NEDİM HAZAR\", \"NEŞE YAŞIN\", \"OKAY KARACAN\",\n",
        "    \"ÖZGE BAŞAK TANELİ\", \"REHA MUHTAR\", \"RIDVAN DİLMEN\", \"RUHAT MENGİ\",\n",
        "    \"SELİM İLERİ\", \"TARHAN ERDEM\", \"UFUK BOZKIR\", \"YAŞAR SEYMAN\"\n",
        "]\n",
        "\n",
        "# Function to sort according to Turkish alphabet\n",
        "def turkish_sort(text):\n",
        "    turkish_alphabet = 'AÂBCÇDEFGĞHIİÎJKLMNOÖPRSŞTUÜVYZ'\n",
        "    return [turkish_alphabet.index(c) for c in text.upper() if c in turkish_alphabet]\n",
        "\n",
        "# Alphabetically sorted class mapping according to Turkish alphabet\n",
        "sorted_authors = sorted(authors, key=turkish_sort)\n",
        "\n",
        "# Lists for storing data\n",
        "all_articles = []\n",
        "labels = []\n",
        "\n",
        "# Reading files from author folders\n",
        "for author in sorted_authors:\n",
        "    folder_path = os.path.join(data_path, author)\n",
        "    if os.path.exists(folder_path):\n",
        "        files = glob.glob(os.path.join(folder_path, '*.txt'))\n",
        "        for file in files:\n",
        "            try:\n",
        "                # Reading the file with ISO-8859-9\n",
        "                with open(file, 'r', encoding='ISO-8859-9') as f:\n",
        "                    article = f.read().strip()\n",
        "                    all_articles.append(article)\n",
        "                    labels.append(author)\n",
        "            except UnicodeDecodeError as e:\n",
        "                print(f\"Error reading file {file}: {e}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Unexpected error with file {file}: {e}\")\n",
        "\n",
        "# Data control\n",
        "print(f\"Total number of articles: {len(all_articles)}\")\n",
        "print(f\"Total number of labels: {len(labels)}\")\n",
        "print(f\"Sample article: {all_articles[0][:200]}...\") # A preview of the first article\n",
        "print(f\"Sample label: {labels[0]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBNydUosmeYZ"
      },
      "source": [
        "# Data Prepocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u8F9wjIAh7WZ",
        "outputId": "e095d050-8191-46c8-cfa3-9caf5e7e631f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jpype1\n",
            "  Downloading jpype1-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from jpype1) (24.2)\n",
            "Downloading jpype1-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/493.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.9/493.9 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jpype1\n",
            "Successfully installed jpype1-1.5.1\n",
            "Collecting zemberek-python\n",
            "  Downloading zemberek_python-0.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting antlr4-python3-runtime==4.8 (from zemberek-python)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from zemberek-python) (1.26.4)\n",
            "Downloading zemberek_python-0.2.3-py3-none-any.whl (95.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.1/95.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141214 sha256=772634010af65d05d018af705387cfa0420c480935a0a4e2aa0e03ae521bc430\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/10/be/9a70640a3a60ed4a7e1a45e49bb9f58b04692d5d7b517bd39e\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, zemberek-python\n",
            "Successfully installed antlr4-python3-runtime-4.8 zemberek-python-0.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install jpype1 #Since zemberek is written in java, we need to install jpeg1\n",
        "!pip install zemberek-python #zembereki installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHg26HDSmkje",
        "outputId": "748a7597-2ad3-4636-8644-1a82a02588ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:zemberek.morphology.turkish_morphology:TurkishMorphology instance initialized in 18.37812614440918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-24 11:12:33,831 - zemberek.morphology.turkish_morphology - INFO\n",
            "Msg: TurkishMorphology instance initialized in 18.37812614440918\n",
            "\n",
            "Total number of processed articles: 1500\n",
            "Sample processed article: de iki fark devre beşiktaş rahat oyna çok gol kaçır ama karabük o kadar dağınık ve kötü ki bu maç için fazla bir şey söyle de bir anlam yok devre maç bak ol ekrem hayat bul gol pozisyon bul sağ gel so...\n"
          ]
        }
      ],
      "source": [
        "from zemberek.tokenization import TurkishTokenizer\n",
        "from zemberek.morphology import TurkishMorphology\n",
        "import string\n",
        "\n",
        "# start Zemberek Morphology\n",
        "morphology = TurkishMorphology.create_with_defaults()\n",
        "tokenizer = TurkishTokenizer.DEFAULT\n",
        "\n",
        "# convert lovercase\n",
        "def to_lowercase(text):\n",
        "    return text.lower()\n",
        "\n",
        "# Tokenization\n",
        "def tokenize_text(text):\n",
        "    return tokenizer.tokenize(text)\n",
        "\n",
        "# Clean up punctuation\n",
        "def remove_punctuation(tokens):\n",
        "    return [token for token in tokens if token.content not in string.punctuation]\n",
        "\n",
        "# stemming\n",
        "def apply_stemming(tokens, morphology):\n",
        "    stemmed_tokens = []\n",
        "    for token in tokens:\n",
        "        if '#' in token.content or any(char in string.punctuation for char in token.content):\n",
        "            continue\n",
        "\n",
        "        analysis = morphology.analyze(token.normalized)\n",
        "        if analysis.analysis_results:  # Add words that can be analyzed\n",
        "            stemmed_tokens.append(analysis.analysis_results[0].item.root)\n",
        "    return stemmed_tokens\n",
        "\n",
        "# Processing on all articles\n",
        "processed_articles = []\n",
        "for article in all_articles:\n",
        "    try:\n",
        "        # 1. convert lowercase\n",
        "        lowercased_article = to_lowercase(article)\n",
        "\n",
        "        # 2. Tokenization\n",
        "        tokens = tokenize_text(lowercased_article)\n",
        "\n",
        "        # 3. clear punctuation\n",
        "        cleaned_tokens = remove_punctuation(tokens)\n",
        "\n",
        "        # 4. apply stemming\n",
        "        stemmed_tokens = apply_stemming(cleaned_tokens, morphology)\n",
        "\n",
        "        # Save the processed data\n",
        "        processed_articles.append(\" \".join(stemmed_tokens))\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing article: {e}\")\n",
        "\n",
        "# Control of processed data\n",
        "print(f\"Total number of processed articles: {len(processed_articles)}\")\n",
        "print(f\"Sample processed article: {processed_articles[0][:200]}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbNEnv6I0WtJ",
        "outputId": "255a19fc-58ca-4304-c3e8-709002dfef96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-24 11:34:57,673 - numexpr.utils - INFO\n",
            "Msg: NumExpr defaulting to 2 threads.\n",
            "\n",
            "TF-IDF table saved as '/content/tfidf_values.csv'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Processed articles and labels will be used for TF-IDF\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(processed_articles)\n",
        "\n",
        "# Convert TF-IDF results to DataFrame\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "# Adding labels\n",
        "tfidf_df['class'] = labels\n",
        "\n",
        "# Sort the documents and name them as 'doc1', 'doc2', ...\n",
        "tfidf_df.index = [f\"doc{doc_id + 1}\" for doc_id in range(len(processed_articles))]\n",
        "\n",
        "# Save as CSV\n",
        "output_path = '/content/tfidf_values.csv'\n",
        "tfidf_df.to_csv(output_path, sep=';', index=True, encoding='utf-8-sig')\n",
        "print(f\"TF-IDF table saved as '{output_path}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbeemXpC6UJl",
        "outputId": "8350431c-0114-489b-9f43-c8b787833ae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1:\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      class1       0.83      1.00      0.91        10\n",
            "      class2       0.77      1.00      0.87        10\n",
            "      class3       0.91      1.00      0.95        10\n",
            "      class4       1.00      1.00      1.00        10\n",
            "      class5       1.00      1.00      1.00        10\n",
            "      class6       1.00      1.00      1.00        10\n",
            "      class7       1.00      0.90      0.95        10\n",
            "      class8       1.00      1.00      1.00        10\n",
            "      class9       0.90      0.90      0.90        10\n",
            "     class10       0.91      1.00      0.95        10\n",
            "     class11       0.82      0.90      0.86        10\n",
            "     class12       0.73      0.80      0.76        10\n",
            "     class13       0.88      0.70      0.78        10\n",
            "     class14       1.00      1.00      1.00        10\n",
            "     class15       1.00      0.90      0.95        10\n",
            "     class16       1.00      1.00      1.00        10\n",
            "     class17       0.89      0.80      0.84        10\n",
            "     class18       1.00      1.00      1.00        10\n",
            "     class19       1.00      1.00      1.00        10\n",
            "     class20       0.90      0.90      0.90        10\n",
            "     class21       0.82      0.90      0.86        10\n",
            "     class22       1.00      0.50      0.67        10\n",
            "     class23       0.89      0.80      0.84        10\n",
            "     class24       1.00      1.00      1.00        10\n",
            "     class25       0.77      1.00      0.87        10\n",
            "     class26       1.00      0.70      0.82        10\n",
            "     class27       0.91      1.00      0.95        10\n",
            "     class28       1.00      1.00      1.00        10\n",
            "     class29       1.00      1.00      1.00        10\n",
            "     class30       0.80      0.80      0.80        10\n",
            "\n",
            "    accuracy                           0.92       300\n",
            "   macro avg       0.92      0.92      0.91       300\n",
            "weighted avg       0.92      0.92      0.91       300\n",
            "\n",
            "\n",
            "Fold 2:\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      class1       0.82      0.90      0.86        10\n",
            "      class2       0.60      0.60      0.60        10\n",
            "      class3       1.00      0.80      0.89        10\n",
            "      class4       1.00      0.90      0.95        10\n",
            "      class5       1.00      1.00      1.00        10\n",
            "      class6       1.00      1.00      1.00        10\n",
            "      class7       0.91      1.00      0.95        10\n",
            "      class8       1.00      1.00      1.00        10\n",
            "      class9       1.00      1.00      1.00        10\n",
            "     class10       0.91      1.00      0.95        10\n",
            "     class11       0.75      0.90      0.82        10\n",
            "     class12       0.75      0.90      0.82        10\n",
            "     class13       1.00      1.00      1.00        10\n",
            "     class14       0.91      1.00      0.95        10\n",
            "     class15       1.00      1.00      1.00        10\n",
            "     class16       1.00      1.00      1.00        10\n",
            "     class17       1.00      0.90      0.95        10\n",
            "     class18       1.00      0.90      0.95        10\n",
            "     class19       1.00      1.00      1.00        10\n",
            "     class20       1.00      0.90      0.95        10\n",
            "     class21       0.90      0.90      0.90        10\n",
            "     class22       0.82      0.90      0.86        10\n",
            "     class23       0.91      1.00      0.95        10\n",
            "     class24       1.00      0.80      0.89        10\n",
            "     class25       1.00      1.00      1.00        10\n",
            "     class26       1.00      0.90      0.95        10\n",
            "     class27       0.82      0.90      0.86        10\n",
            "     class28       0.80      0.80      0.80        10\n",
            "     class29       1.00      0.90      0.95        10\n",
            "     class30       0.78      0.70      0.74        10\n",
            "\n",
            "    accuracy                           0.92       300\n",
            "   macro avg       0.92      0.92      0.92       300\n",
            "weighted avg       0.92      0.92      0.92       300\n",
            "\n",
            "\n",
            "Fold 3:\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      class1       0.90      0.90      0.90        10\n",
            "      class2       0.71      1.00      0.83        10\n",
            "      class3       0.80      0.80      0.80        10\n",
            "      class4       0.90      0.90      0.90        10\n",
            "      class5       1.00      0.90      0.95        10\n",
            "      class6       1.00      0.80      0.89        10\n",
            "      class7       1.00      1.00      1.00        10\n",
            "      class8       1.00      0.80      0.89        10\n",
            "      class9       1.00      0.90      0.95        10\n",
            "     class10       0.83      1.00      0.91        10\n",
            "     class11       0.60      0.90      0.72        10\n",
            "     class12       0.67      0.60      0.63        10\n",
            "     class13       1.00      1.00      1.00        10\n",
            "     class14       1.00      1.00      1.00        10\n",
            "     class15       0.90      0.90      0.90        10\n",
            "     class16       0.91      1.00      0.95        10\n",
            "     class17       1.00      0.90      0.95        10\n",
            "     class18       1.00      1.00      1.00        10\n",
            "     class19       1.00      0.90      0.95        10\n",
            "     class20       0.90      0.90      0.90        10\n",
            "     class21       0.91      1.00      0.95        10\n",
            "     class22       1.00      0.80      0.89        10\n",
            "     class23       1.00      0.80      0.89        10\n",
            "     class24       1.00      0.80      0.89        10\n",
            "     class25       0.91      1.00      0.95        10\n",
            "     class26       1.00      0.90      0.95        10\n",
            "     class27       0.69      0.90      0.78        10\n",
            "     class28       0.80      0.80      0.80        10\n",
            "     class29       0.90      0.90      0.90        10\n",
            "     class30       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.90       300\n",
            "   macro avg       0.91      0.90      0.90       300\n",
            "weighted avg       0.91      0.90      0.90       300\n",
            "\n",
            "\n",
            "Fold 4:\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      class1       0.90      0.90      0.90        10\n",
            "      class2       0.69      0.90      0.78        10\n",
            "      class3       0.82      0.90      0.86        10\n",
            "      class4       0.90      0.90      0.90        10\n",
            "      class5       1.00      1.00      1.00        10\n",
            "      class6       0.77      1.00      0.87        10\n",
            "      class7       1.00      0.90      0.95        10\n",
            "      class8       1.00      0.90      0.95        10\n",
            "      class9       1.00      1.00      1.00        10\n",
            "     class10       0.90      0.90      0.90        10\n",
            "     class11       1.00      0.60      0.75        10\n",
            "     class12       0.90      0.90      0.90        10\n",
            "     class13       0.89      0.80      0.84        10\n",
            "     class14       0.77      1.00      0.87        10\n",
            "     class15       1.00      1.00      1.00        10\n",
            "     class16       0.82      0.90      0.86        10\n",
            "     class17       1.00      0.80      0.89        10\n",
            "     class18       1.00      1.00      1.00        10\n",
            "     class19       0.77      1.00      0.87        10\n",
            "     class20       0.91      1.00      0.95        10\n",
            "     class21       1.00      0.70      0.82        10\n",
            "     class22       0.91      1.00      0.95        10\n",
            "     class23       1.00      0.80      0.89        10\n",
            "     class24       0.86      0.60      0.71        10\n",
            "     class25       0.91      1.00      0.95        10\n",
            "     class26       1.00      1.00      1.00        10\n",
            "     class27       0.90      0.90      0.90        10\n",
            "     class28       1.00      1.00      1.00        10\n",
            "     class29       0.91      1.00      0.95        10\n",
            "     class30       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.91       300\n",
            "   macro avg       0.92      0.91      0.91       300\n",
            "weighted avg       0.92      0.91      0.91       300\n",
            "\n",
            "\n",
            "Fold 5:\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      class1       0.91      1.00      0.95        10\n",
            "      class2       0.82      0.90      0.86        10\n",
            "      class3       0.67      0.80      0.73        10\n",
            "      class4       1.00      1.00      1.00        10\n",
            "      class5       1.00      0.90      0.95        10\n",
            "      class6       0.89      0.80      0.84        10\n",
            "      class7       1.00      1.00      1.00        10\n",
            "      class8       1.00      0.90      0.95        10\n",
            "      class9       1.00      1.00      1.00        10\n",
            "     class10       1.00      1.00      1.00        10\n",
            "     class11       0.60      0.90      0.72        10\n",
            "     class12       0.64      0.70      0.67        10\n",
            "     class13       1.00      0.90      0.95        10\n",
            "     class14       1.00      1.00      1.00        10\n",
            "     class15       0.83      1.00      0.91        10\n",
            "     class16       1.00      0.90      0.95        10\n",
            "     class17       0.90      0.90      0.90        10\n",
            "     class18       1.00      1.00      1.00        10\n",
            "     class19       1.00      0.90      0.95        10\n",
            "     class20       1.00      0.90      0.95        10\n",
            "     class21       0.90      0.90      0.90        10\n",
            "     class22       0.90      0.90      0.90        10\n",
            "     class23       0.90      0.90      0.90        10\n",
            "     class24       0.83      1.00      0.91        10\n",
            "     class25       1.00      1.00      1.00        10\n",
            "     class26       1.00      1.00      1.00        10\n",
            "     class27       1.00      0.70      0.82        10\n",
            "     class28       1.00      0.90      0.95        10\n",
            "     class29       1.00      0.80      0.89        10\n",
            "     class30       0.89      0.80      0.84        10\n",
            "\n",
            "    accuracy                           0.91       300\n",
            "   macro avg       0.92      0.91      0.91       300\n",
            "weighted avg       0.92      0.91      0.91       300\n",
            "\n",
            "\n",
            "Final results saved to 'final_results.xlsx'\n",
            "Average Accuracy: 0.9093333333333333\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Load data from CSV file\n",
        "dataset = pd.read_csv('/content/tfidf_values.csv', sep=';', encoding='utf-8-sig')\n",
        "\n",
        "# Separating TF-IDF features and classes by removing the 'Unnamed: 0' column\n",
        "X = dataset.drop(columns=['class', 'Unnamed: 0']).to_numpy() # TF-IDF feature matrix\n",
        "y = dataset['class'].to_numpy()  # class labels\n",
        "\n",
        "# Sorting and numbering author names in alphabetical order\n",
        "sorted_authors = sorted(set(y))\n",
        "label_mapping = {author: f'class{i+1}' for i, author in enumerate(sorted_authors)}\n",
        "y_mapped = np.array([label_mapping[author] for author in y])\n",
        "\n",
        "# Convert class labels to numeric values\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y_mapped)\n",
        "# Using StratifiedKFold for 5-Fold Cross-Validation\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "accuracy_list = []  # Storing the accuracy results for each fold\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "\n",
        "final_results = {class_name: {'precision': [], 'recall': [], 'f1-score': []} for class_name in label_mapping.values()}\n",
        "\n",
        "# 5-fold cross validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y_encoded), 1):\n",
        "    print(f\"\\nFold {fold}:\")\n",
        "\n",
        "    # Separating training and test sets\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
        "\n",
        "   # Creating and training the SVM model\n",
        "    classifier = SVC(kernel='linear', random_state=42)  #linear kernel\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Making predictions on the test set\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    # Classification report and accuracy score\n",
        "    print(\"Classification Report:\")\n",
        "    target_names = [f'class{i+1}' for i in range(len(sorted_authors))]\n",
        "    report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
        "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "    # Calculate accuracy, precision, recall and F1-score for each fold\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
        "\n",
        "   # Add metrics to the list\n",
        "    accuracy_list.append(accuracy)\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "# Add metrics for each class to final_results\n",
        "    for class_name in label_mapping.values():\n",
        "        final_results[class_name]['precision'].append(report[class_name]['precision'])\n",
        "        final_results[class_name]['recall'].append(report[class_name]['recall'])\n",
        "        final_results[class_name]['f1-score'].append(report[class_name]['f1-score'])\n",
        "\n",
        "# Calculate average metrics for each class\n",
        "final_metrics = {\n",
        "    'Class': [],\n",
        "    'Precision': [],\n",
        "    'Recall': [],\n",
        "    'F1-Score': []\n",
        "}\n",
        "\n",
        "for class_name, metrics in final_results.items():\n",
        "    final_metrics['Class'].append(class_name)\n",
        "    final_metrics['Precision'].append(np.mean(metrics['precision']))\n",
        "    final_metrics['Recall'].append(np.mean(metrics['recall']))\n",
        "    final_metrics['F1-Score'].append(np.mean(metrics['f1-score']))\n",
        "\n",
        "# Calculating overall averages\n",
        "overall_precision = np.mean(precision_list)\n",
        "overall_recall = np.mean(recall_list)\n",
        "overall_f1 = np.mean(f1_list)\n",
        "overall_accuracy = np.mean(accuracy_list)\n",
        "\n",
        "# Adding the overall averages to the table\n",
        "final_metrics['Class'].append('Overall Average')\n",
        "final_metrics['Precision'].append(overall_precision)\n",
        "final_metrics['Recall'].append(overall_recall)\n",
        "final_metrics['F1-Score'].append(overall_f1)\n",
        "\n",
        "final_results_df = pd.DataFrame(final_metrics)\n",
        "\n",
        "# Save the results to an Excel file\n",
        "final_results_df.to_excel('/content/final_results.xlsx', index=False)\n",
        "\n",
        "print(\"\\nFinal results saved to 'final_results.xlsx'\")\n",
        "print(f\"Average Accuracy: {overall_accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}